# docker-compose.yml
version: '3'

services:
  # Service Ollama pour les modèles LLM locaux
  ollama:
    image: ollama/ollama:latest
    container_name: memoire-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./models:/usr/share/ollama/models # Dossier pour les modèles préchargés
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Configuration GPU optionnelle - décommenter si GPU disponible
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    # Utiliser par défaut sans GPU
    command: serve

  # Service backend FastAPI
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: memoire-backend
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./backend:/app
      - ./logs:/app/logs
    environment:
      - RESET_DB=true
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODEL=mistral:7b  # ou llama3:8b
      - DB_PATH=/app/data
      - VECTOR_DB_PATH=/app/data/vectordb
      - SQLITE_DB_PATH=/app/data/memoire.db
      - CACHE_PATH=/app/data/cache
      - EXPORT_PATH=/app/data/exports
      - TEMP_PATH=/app/data/temp
      - LOG_LEVEL=INFO
      - ENABLE_WEBSOCKETS=true
    depends_on:
      - ollama
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: ["/app/scripts/init.sh"]

  # Service frontend Streamlit
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: memoire-frontend
    ports:
      - "8501:8501"
    volumes:
      - ./frontend:/app
      - ./data:/app/data
      - ./logs:/app/logs
    environment:
      - API_URL=http://backend:8000
      - WS_URL=ws://backend:8000/ws
      - STREAMLIT_SERVER_MAX_UPLOAD_SIZE=20
      - STREAMLIT_CLIENT_TOOLBAR_MODE=minimal
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/healthz || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: ["/app/scripts/wait-for-backend.sh"]

  # Service de sauvegarde automatique (optionnel)
  backup:
    image: alpine:latest
    container_name: memoire-backup
    volumes:
      - ./data:/data
      - ./backups:/backups
    command: >
      sh -c "mkdir -p /backups && 
             while true; do 
               timestamp=$$(date +%Y%m%d_%H%M%S); 
               tar -czf /backups/memoire_backup_$$timestamp.tar.gz -C /data .; 
               find /backups -name 'memoire_backup_*.tar.gz' -mtime +7 -delete; 
               sleep 86400; 
             done"
    restart: unless-stopped

  test:
    build:
      context: ./backend
      dockerfile: Dockerfile
    volumes:
      - ./backend:/app
      - ./test_data:/app/test_data
    environment:
      - DB_PATH=/app/test_data
      - VECTOR_DB_PATH=/app/test_data/vectordb
      - SQLITE_DB_PATH=/app/test_data/test_memoire.db
      - EXPORT_PATH=/app/test_data/exports
      - TEST_MODE=true
    command: ["pytest", "-xvs"]

volumes:
  ollama_data: